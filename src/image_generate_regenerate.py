import os
from pathlib import Path
from PIL import Image
import torch
from datetime import datetime

# å‡è®¾ pipeline å’Œ apply_group_offloading å·²ç»æ­£ç¡®å¯¼å…¥
from pipeline import InstantCharacterFluxPipeline
from diffusers.hooks import apply_group_offloading

class ImageGenerator:
    def __init__(self):
        self.ip_adapter_path = '/data/home/lizhijun/llm/flux-hf/InstantCharacter-main/tencent/InstantCharacter/instantcharacter_ip-adapter.bin'
        self.base_model = '/data/home/lizhijun/llm/flux-hf/model/flux-dev'
        self.image_encoder_path = 'google/siglip-so400m-patch14-384'
        self.image_encoder_2_path = 'facebook/dinov2-giant'

        print("Initializing Flux model...")
        self.pipe = InstantCharacterFluxPipeline.from_pretrained(
            self.base_model, torch_dtype=torch.bfloat16
        )
        # offload ä¼˜åŒ–
        for module in [self.pipe.transformer,
                       self.pipe.text_encoder,
                       self.pipe.text_encoder_2,
                       self.pipe.vae]:
            apply_group_offloading(
                module,
                offload_type="leaf_level",
                offload_device=torch.device("cpu"),
                onload_device=torch.device("cuda"),
                use_stream=True,
            )
        self.pipe.init_adapter(
            image_encoder_path=self.image_encoder_path,
            image_encoder_2_path=self.image_encoder_2_path,
            subject_ipadapter_cfg=dict(
                subject_ip_adapter_path=self.ip_adapter_path,
                nb_token=1024
            ),
        )
        print("Flux model initialized.")

    def generate(self, prompt: str, reference_image: str = None,
                 output_path: Path = None, **kwargs) -> Path:
        if output_path is None:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            output_path = Path(f"generated_image_{ts}.png")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        return self._generate_with_flux(prompt, reference_image, output_path, **kwargs)

    def _generate_with_flux(self, prompt, reference_image, output_path, **kwargs):
        ref_img = None
        if reference_image and os.path.exists(reference_image):
            try:
                ref_img = Image.open(reference_image).convert('RGB')
            except:
                pass

        steps = kwargs.get("steps", 30)
        guidance = kwargs.get("guidance_scale", 3.8)
        subj_scale = kwargs.get("subject_scale", 0.9)
        seed = kwargs.get("seed", 42)

        device = "cuda" if torch.cuda.is_available() else "cpu"
        gen = torch.Generator(device=device).manual_seed(seed)

        if ref_img:
            img = self.pipe(
                prompt=prompt,
                num_inference_steps=steps,
                guidance_scale=guidance,
                subject_scale=subj_scale,
                subject_image=ref_img,
                generator=gen,
            ).images[0]
        else:
            img = self.pipe(
                prompt=prompt,
                num_inference_steps=steps,
                guidance_scale=guidance,
                generator=gen,
            ).images[0]

        img.save(output_path)
        return output_path

# ---------------------------------
#           ä¸»ç¨‹åºéƒ¨åˆ†
# ---------------------------------
if __name__ == "__main__":
    # --- é…ç½®åŒº ---
    input_content_dir = Path("generated_video_content/æ˜¥å¤©åœ¨å“ªé‡Œ_20250614_002954")
    reference_image_path = 'img/12.png'
    output_images_subfolder = "generated_images"
    base_seed = 1234

    # âœ¨ æ ¸å¿ƒé…ç½®ï¼šæŒ‡å®šè¦ç”Ÿæˆçš„åœºæ¬¡åˆ—è¡¨ï¼Œä»¥åŠæ¯ä¸ªåœºæ¬¡ç”Ÿæˆå‡ å¼ å›¾ç‰‡
    scene_indices_to_generate = [5]  # è¦å¤„ç†çš„åœºæ¬¡å·
    num_images_per_scene = 3                 # æ¯ä¸ªåœºæ¬¡ç”Ÿæˆ 3 å¼ å›¾

    # override_prompts = {}
    
    # âœ¨ æ›´æ–°åçš„ Prompt è¦†ç›–å­—å…¸ (ä½¿ç”¨â€œè§†è§‰æè¿°â€ç­–ç•¥)
    override_prompts = {
        4: "Anime style, high quality, consistent character design, the girl sits on a mossy rock by a babbling brook, letting her bare feet dangle in the clear, cool water. She gently kicks, sending small, sparkling ripples across the surface where her reflection shimmers. Low-angle shot focusing on her feet and the splashing water, serene and refreshing.",
        5: "Anime style, high quality, consistent character design, the girl stands in a sunny field of wildflowers, holding a fluffy dandelion clock. She closes her eyes and gently blows, sending a cloud of seeds drifting on the breeze. Her hair flutters softly. Medium close-up shot capturing the glittering seeds in the golden light, a moment of simple, pure joy."
    }

    generation_params = {
        "steps": 30,
        "guidance_scale": 3.8,
        "subject_scale": 0.9,
    }
    # --- é…ç½®ç»“æŸ ---

    # 1. è¯»å–æ‰€æœ‰ prompt
    prompts_file = input_content_dir / "img2img_prompts.txt"
    if not prompts_file.exists():
        print(f"Error: {prompts_file} ä¸å­˜åœ¨ã€‚")
        exit(1)
    with open(prompts_file, "r", encoding="utf-8") as f:
        all_prompts = [l.strip() for l in f if l.strip()]

    # 2. å‡†å¤‡è¾“å‡ºç›®å½•
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = input_content_dir / output_images_subfolder / f"rerun_{ts}"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸš€ å°†ä¸ºåœºæ¬¡ {scene_indices_to_generate} å„ç”Ÿæˆ {num_images_per_scene} å¼ å›¾ç‰‡ã€‚")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    # 3. åˆå§‹åŒ– Flux ç”Ÿæˆå™¨
    generator = ImageGenerator()

    # 4. å¾ªç¯ç”Ÿæˆ
    results = []
    # å¤–å±‚å¾ªç¯ï¼šéå†æŒ‡å®šçš„æ¯ä¸ªåœºæ¬¡
    for idx in scene_indices_to_generate:
        if idx < 1 or idx > len(all_prompts):
            print(f"âš ï¸ åœºæ¬¡ {idx} è¶Šç•Œï¼Œè·³è¿‡ã€‚")
            continue

        prompt = override_prompts.get(idx, all_prompts[idx - 1])
        print(f"\n- - - - - - - - - - - - - - - - - - - - - - -")
        print(f"ğŸ”„ å¼€å§‹å¤„ç†åœºæ¬¡ {idx:02d}ï¼Œå°†ç”Ÿæˆ {num_images_per_scene} å¼ å›¾ç‰‡...")
        print(f"   Prompt: {prompt}")

        # å†…å±‚å¾ªç¯ï¼šä¸ºå½“å‰åœºæ¬¡ç”ŸæˆæŒ‡å®šæ•°é‡çš„å›¾ç‰‡
        for i in range(num_images_per_scene):
            run_num = i + 1
            # ç¡®ä¿æ¯å¼ å›¾éƒ½æœ‰å”¯ä¸€çš„ seed å’Œæ–‡ä»¶å
            # æ·»åŠ ä¸€ä¸ªè¾ƒå¤§çš„æ•°ä¹˜ä»¥åœºæ¬¡å·ï¼Œé¿å…ä¸åŒåœºæ¬¡çš„seedè¿‡äºæ¥è¿‘
            seed = base_seed + (idx * 1000) + i 
            out_path = output_dir / f"scene{idx:02d}_run{run_num:02d}.png"
            
            print(f"  -> æ­£åœ¨ç”Ÿæˆç¬¬ {run_num}/{num_images_per_scene} å¼ ... (Seed: {seed})")
            
            try:
                p = generator.generate(
                    prompt=prompt,
                    reference_image=reference_image_path,
                    output_path=out_path,
                    seed=seed,
                    **generation_params
                )
                print(f"  âœ… ä¿å­˜æˆåŠŸ: {p.name}")
                results.append(p)
            except Exception as e:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {len(results)} å¼ å›¾ç‰‡ï¼Œä¿å­˜åœ¨ç›®å½•ï¼š{output_dir}")