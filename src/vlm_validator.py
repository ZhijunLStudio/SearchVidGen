import os
import base64
import json
import logging
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
from PIL import Image
from io import BytesIO
from openai import OpenAI
import time
import concurrent.futures

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VLMValidator:
    """è§†è§‰è¯­è¨€æ¨¡å‹éªŒè¯å™¨"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "gpt-4o-mini"):
        """
        åˆå§‹åŒ–VLMéªŒè¯å™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.model = model
        
        client_args = {"api_key": api_key}
        if base_url:
            client_args["base_url"] = base_url
            
        self.client = OpenAI(**client_args)
        
        # åŠ è½½éªŒè¯æç¤ºè¯é…ç½®
        self.load_validation_prompts()
        
        logger.info(f"VLMéªŒè¯å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {model}")

    def load_validation_prompts(self):
        """åŠ è½½éªŒè¯æç¤ºè¯é…ç½®"""
        try:
            config_path = Path("config/prompts.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    self.validation_prompts = config.get("validation_prompts", {})
            else:
                # é»˜è®¤éªŒè¯æç¤ºè¯
                self.validation_prompts = {
                    "image_content_analysis": """
è¯·ä»”ç»†è§‚å¯Ÿè¿™å¼ å›¾ç‰‡ï¼Œè¯¦ç»†æè¿°ä»¥ä¸‹å†…å®¹ï¼š

1. **ä¸»è¦äººç‰©æˆ–è§’è‰²**ï¼š
   - å¤–è§‚ç‰¹å¾ï¼ˆå‘å‹ã€æœè£…ã€ä½“å‹ç­‰ï¼‰
   - é¢éƒ¨è¡¨æƒ…å’Œæƒ…æ„ŸçŠ¶æ€
   - å§¿åŠ¿å’ŒåŠ¨ä½œ

2. **åœºæ™¯ç¯å¢ƒ**ï¼š
   - èƒŒæ™¯è®¾ç½®å’Œç¯å¢ƒæ°›å›´
   - é‡è¦çš„é“å…·æˆ–ç‰©ä½“
   - å…‰çº¿å’Œè‰²å½©åŸºè°ƒ

3. **åŠ¨ä½œå’Œè¡Œä¸º**ï¼š
   - è§’è‰²æ­£åœ¨è¿›è¡Œçš„æ´»åŠ¨
   - åŠ¨ä½œçš„åŠ¨æ€æ„Ÿå’Œè‡ªç„¶åº¦
   - ä¸ç¯å¢ƒçš„äº’åŠ¨

4. **æ„å›¾å’Œè§†è§‰æ•ˆæœ**ï¼š
   - æ•´ä½“æ„å›¾å’Œè§†è§’
   - ç”»é¢çš„å¹³è¡¡æ„Ÿå’Œç„¦ç‚¹
   - è‰ºæœ¯é£æ ¼å’Œè´¨é‡

5. **æƒ…æ„Ÿè¡¨è¾¾å’Œæ•…äº‹æ„Ÿ**ï¼š
   - ä¼ è¾¾çš„æƒ…ç»ªå’Œæ°›å›´
   - æ˜¯å¦å…·æœ‰æ•…äº‹æ€§
   - è§‚ä¼—çš„è§†è§‰ä½“éªŒ

è¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°ï¼Œæ¯ä¸ªæ–¹é¢éƒ½è¦å…·ä½“åˆ†æã€‚
""",

                    "prompt_consistency_check": """
è¯·å°†è¿™å¼ å›¾ç‰‡ä¸ä»¥ä¸‹æç¤ºè¯è¿›è¡Œå¯¹æ¯”åˆ†æï¼š

**åŸå§‹æç¤ºè¯ï¼š** {prompt}

è¯·è¯„ä¼°ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

1. **å†…å®¹ä¸€è‡´æ€§**ï¼š
   - å›¾ç‰‡å†…å®¹ä¸æç¤ºè¯æè¿°çš„åŒ¹é…ç¨‹åº¦ï¼ˆ1-10åˆ†ï¼‰
   - å“ªäº›å…³é”®å…ƒç´ ä½“ç°å¾—å¾ˆå¥½ï¼Ÿ
   - å“ªäº›é‡è¦å…ƒç´ ç¼ºå¤±æˆ–ä¸å‡†ç¡®ï¼Ÿ

2. **è§’è‰²ä¸€è‡´æ€§**ï¼š
   - è§’è‰²å¤–è§‚æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Ÿ
   - è§’è‰²è¡¨æƒ…å’Œå§¿æ€æ˜¯å¦åˆé€‚ï¼Ÿ
   - ä¸å‚è€ƒå›¾çš„ä¸€è‡´æ€§å¦‚ä½•ï¼Ÿ

3. **åœºæ™¯è¿˜åŸåº¦**ï¼š
   - èƒŒæ™¯ç¯å¢ƒæ˜¯å¦ç¬¦åˆæè¿°ï¼Ÿ
   - æ°›å›´å’Œå…‰çº¿æ•ˆæœå¦‚ä½•ï¼Ÿ
   - é“å…·å’Œç»†èŠ‚æ˜¯å¦åˆ°ä½ï¼Ÿ

4. **è‰ºæœ¯è´¨é‡**ï¼š
   - æ•´ä½“ç”»é¢è´¨é‡è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
   - æ„å›¾å’Œè‰²å½©æ­é…
   - æ˜¯å¦è¾¾åˆ°ä¸“ä¸šæ ‡å‡†ï¼Ÿ

5. **æ”¹è¿›å»ºè®®**ï¼š
   - å¦‚æœé‡æ–°ç”Ÿæˆï¼Œåº”è¯¥å¼ºè°ƒå“ªäº›å…³é”®è¯ï¼Ÿ
   - å“ªäº›æè¿°éœ€è¦æ›´åŠ å…·ä½“ï¼Ÿ
   - æ˜¯å¦å»ºè®®è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼Ÿ

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ç»™å‡ºå…·ä½“çš„è¯„åˆ†å’Œå»ºè®®ã€‚
""",

                    "batch_validation_summary": """
ä½ å·²ç»åˆ†æäº†ä¸€ç³»åˆ—åœºæ™¯å›¾ç‰‡ï¼Œè¯·æä¾›æ•´ä½“çš„éªŒè¯æ€»ç»“ï¼š

1. **æ•´ä½“è´¨é‡è¯„ä¼°**ï¼š
   - æ‰€æœ‰å›¾ç‰‡çš„å¹³å‡è´¨é‡æ°´å¹³
   - æœ€ä½³å’Œæœ€å·®çš„åœºæ™¯åˆ†æ
   - æ•´ä½“é£æ ¼ä¸€è‡´æ€§å¦‚ä½•ï¼Ÿ

2. **è§’è‰²ä¸€è‡´æ€§åˆ†æ**ï¼š
   - è§’è‰²åœ¨ä¸åŒåœºæ™¯ä¸­çš„ä¸€è‡´æ€§
   - å“ªäº›åœºæ™¯çš„è§’è‰²è¡¨ç°æœ€å¥½ï¼Ÿ
   - éœ€è¦é‡ç‚¹æ”¹è¿›çš„è§’è‰²æ–¹é¢

3. **æ•…äº‹è¿è´¯æ€§**ï¼š
   - åœºæ™¯ä¹‹é—´çš„é€»è¾‘è¿æ¥
   - æ—¶é—´å‘å±•çš„åˆç†æ€§
   - æƒ…èŠ‚æ¨è¿›çš„æµç•…åº¦

4. **æŠ€æœ¯é—®é¢˜æ€»ç»“**ï¼š
   - å¸¸è§çš„ç”Ÿæˆé—®é¢˜
   - éœ€è¦ä¼˜åŒ–çš„æŠ€æœ¯å‚æ•°
   - æç¤ºè¯æ”¹è¿›æ–¹å‘

5. **ä¼˜åŒ–å»ºè®®**ï¼š
   - æ•´ä½“é¡¹ç›®çš„æ”¹è¿›æ–¹æ¡ˆ
   - ä¼˜å…ˆçº§æœ€é«˜çš„ä¿®æ”¹å»ºè®®
   - ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’

è¯·æä¾›ä¸“ä¸šã€è¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚
"""
                }
        except Exception as e:
            logger.warning(f"åŠ è½½éªŒè¯æç¤ºè¯é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            pass

    def encode_image_to_base64(self, image_path: Path) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        try:
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # å‹ç¼©å›¾ç‰‡ä»¥å‡å°‘APIè°ƒç”¨æˆæœ¬
                max_size = (1024, 1024)
                img.thumbnail(max_size, Image.Resampling.LANCZOS)
                
                # ç¼–ç ä¸ºbase64
                buffer = BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                image_bytes = buffer.getvalue()
                
                return base64.b64encode(image_bytes).decode('utf-8')
        except Exception as e:
            logger.error(f"å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path}: {e}")
            return None

    def validate_single_image(self, image_path: Path, prompt: str = None, 
                            validation_type: str = "content_analysis") -> Dict[str, Any]:
        """
        éªŒè¯å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: åŸå§‹ç”Ÿæˆæç¤ºè¯
            validation_type: éªŒè¯ç±»å‹ ("content_analysis" æˆ– "prompt_consistency")
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        try:
            # ç¼–ç å›¾ç‰‡
            base64_image = self.encode_image_to_base64(image_path)
            if not base64_image:
                return {
                    "success": False,
                    "error": "å›¾ç‰‡ç¼–ç å¤±è´¥",
                    "image_path": str(image_path)
                }
            
            # é€‰æ‹©éªŒè¯æç¤ºè¯
            if validation_type == "content_analysis":
                system_prompt = self.validation_prompts["image_content_analysis"]
            elif validation_type == "prompt_consistency" and prompt:
                system_prompt = self.validation_prompts["prompt_consistency_check"].format(prompt=prompt)
            else:
                return {
                    "success": False,
                    "error": "æ— æ•ˆçš„éªŒè¯ç±»å‹æˆ–ç¼ºå°‘æç¤ºè¯",
                    "image_path": str(image_path)
                }
            
            # æ„å»ºAPIè¯·æ±‚
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": system_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            # è°ƒç”¨API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1500,
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content
            
            return {
                "success": True,
                "image_path": str(image_path),
                "analysis": analysis,
                "validation_type": validation_type,
                "prompt": prompt if prompt else None,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            logger.error(f"éªŒè¯å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return {
                "success": False,
                "error": str(e),
                "image_path": str(image_path)
            }

    def validate_batch_images(self, project_dir: Path, max_workers: int = 3) -> Dict[str, Any]:
        """
        æ‰¹é‡éªŒè¯é¡¹ç›®ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        
        Args:
            project_dir: é¡¹ç›®ç›®å½•è·¯å¾„
            max_workers: å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            æ‰¹é‡éªŒè¯ç»“æœ
        """
        try:
            # æ£€æŸ¥é¡¹ç›®ç›®å½•
            images_dir = project_dir / "generated_images"
            if not images_dir.exists():
                return {
                    "success": False,
                    "error": "æ‰¾ä¸åˆ°å›¾ç‰‡ç›®å½•",
                    "project_dir": str(project_dir)
                }
            
            # è¯»å–æç¤ºè¯æ–‡ä»¶
            prompts_file = project_dir / "img2img_prompts.txt"
            prompts = []
            if prompts_file.exists():
                with open(prompts_file, 'r', encoding='utf-8') as f:
                    prompts = [line.strip() for line in f if line.strip()]
            
            # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            image_files = sorted([f for f in images_dir.glob("*.png") if f.is_file()])
            
            if not image_files:
                return {
                    "success": False,
                    "error": "æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶",
                    "project_dir": str(project_dir)
                }
            
            logger.info(f"å¼€å§‹æ‰¹é‡éªŒè¯ {len(image_files)} å¼ å›¾ç‰‡")
            
            # å¹¶å‘å¤„ç†å›¾ç‰‡éªŒè¯
            validation_results = []
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰éªŒè¯ä»»åŠ¡
                future_to_image = {}
                
                for i, image_path in enumerate(image_files):
                    # è·å–å¯¹åº”çš„æç¤ºè¯
                    prompt = prompts[i] if i < len(prompts) else None
                    
                    # æäº¤éªŒè¯ä»»åŠ¡
                    future = executor.submit(
                        self.validate_single_image,
                        image_path,
                        prompt,
                        "prompt_consistency" if prompt else "content_analysis"
                    )
                    future_to_image[future] = (image_path, prompt)
                
                # æ”¶é›†ç»“æœ
                for future in concurrent.futures.as_completed(future_to_image):
                    image_path, prompt = future_to_image[future]
                    try:
                        result = future.result()
                        validation_results.append(result)
                        
                        if result["success"]:
                            logger.info(f"âœ… éªŒè¯å®Œæˆ: {image_path.name}")
                        else:
                            logger.error(f"âŒ éªŒè¯å¤±è´¥: {image_path.name} - {result.get('error', 'Unknown error')}")
                            
                    except Exception as e:
                        logger.error(f"éªŒè¯ä»»åŠ¡å¼‚å¸¸ {image_path}: {e}")
                        validation_results.append({
                            "success": False,
                            "error": str(e),
                            "image_path": str(image_path)
                        })
            
            # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            summary = self._generate_validation_summary(validation_results)
            
            # ä¿å­˜éªŒè¯ç»“æœ
            self._save_validation_results(project_dir, validation_results, summary)
            
            return {
                "success": True,
                "project_dir": str(project_dir),
                "total_images": len(image_files),
                "successful_validations": len([r for r in validation_results if r["success"]]),
                "validation_results": validation_results,
                "summary": summary,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            logger.error(f"æ‰¹é‡éªŒè¯å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "project_dir": str(project_dir)
            }

    def _generate_validation_summary(self, validation_results: List[Dict]) -> str:
        """ç”ŸæˆéªŒè¯æ€»ç»“æŠ¥å‘Š"""
        successful_results = [r for r in validation_results if r["success"]]
        failed_results = [r for r in validation_results if not r["success"]]
        
        summary_lines = [
            "# ğŸ” å›¾ç‰‡éªŒè¯æ€»ç»“æŠ¥å‘Š",
            f"ğŸ“Š **éªŒè¯ç»Ÿè®¡**: æ€»è®¡ {len(validation_results)} å¼ å›¾ç‰‡",
            f"âœ… **æˆåŠŸéªŒè¯**: {len(successful_results)} å¼ ",
            f"âŒ **éªŒè¯å¤±è´¥**: {len(failed_results)} å¼ ",
            "",
        ]
        
        if successful_results:
            summary_lines.extend([
                "## ğŸ“‹ éªŒè¯ç»“æœè¯¦æƒ…",
                ""
            ])
            
            for i, result in enumerate(successful_results, 1):
                image_name = Path(result["image_path"]).name
                summary_lines.extend([
                    f"### {i}. {image_name}",
                    f"**éªŒè¯æ—¶é—´**: {result.get('timestamp', 'Unknown')}",
                    f"**åˆ†æç»“æœ**:",
                    result["analysis"][:200] + "..." if len(result["analysis"]) > 200 else result["analysis"],
                    ""
                ])
        
        if failed_results:
            summary_lines.extend([
                "## âŒ éªŒè¯å¤±è´¥çš„å›¾ç‰‡",
                ""
            ])
            
            for result in failed_results:
                image_name = Path(result["image_path"]).name
                summary_lines.append(f"- **{image_name}**: {result.get('error', 'Unknown error')}")
        
        summary_lines.extend([
            "",
            "## ğŸ’¡ æ”¹è¿›å»ºè®®",
            "",
            "1. å¯¹äºéªŒè¯å¤±è´¥çš„å›¾ç‰‡ï¼Œå»ºè®®æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å®Œæ•´æ€§",
            "2. æ ¹æ®åˆ†æç»“æœä¼˜åŒ–æç¤ºè¯çš„å…·ä½“æè¿°",
            "3. è€ƒè™‘è°ƒæ•´ç”Ÿæˆå‚æ•°ä»¥æé«˜å›¾ç‰‡è´¨é‡",
            "4. é‡ç‚¹å…³æ³¨è§’è‰²ä¸€è‡´æ€§å’Œåœºæ™¯è¿è´¯æ€§",
            "",
            f"ğŸ“… **æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}"
        ])
        
        return "\n".join(summary_lines)

    def _save_validation_results(self, project_dir: Path, validation_results: List[Dict], summary: str):
        """ä¿å­˜éªŒè¯ç»“æœåˆ°æ–‡ä»¶"""
        try:
            # ä¿å­˜è¯¦ç»†ç»“æœJSON
            results_file = project_dir / "validation_results.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(validation_results, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æ€»ç»“æŠ¥å‘Š
            summary_file = project_dir / "validation_summary.md"
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            # ä¿å­˜ç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š
            simple_report_file = project_dir / "validation_report.txt"
            with open(simple_report_file, 'w', encoding='utf-8') as f:
                successful_count = len([r for r in validation_results if r["success"]])
                f.write(f"éªŒè¯å®Œæˆ: {successful_count}/{len(validation_results)} å¼ å›¾ç‰‡éªŒè¯æˆåŠŸ\n\n")
                
                for i, result in enumerate(validation_results, 1):
                    if result["success"]:
                        image_name = Path(result["image_path"]).name
                        f.write(f"{i}. {image_name}: âœ… éªŒè¯é€šè¿‡\n")
                        # æå–å…³é”®ä¿¡æ¯
                        analysis = result["analysis"]
                        if "è¯„åˆ†" in analysis or "åˆ†" in analysis:
                            score_lines = [line for line in analysis.split('\n') if 'åˆ†' in line][:2]
                            for line in score_lines:
                                f.write(f"   {line.strip()}\n")
                    else:
                        image_name = Path(result["image_path"]).name
                        f.write(f"{i}. {image_name}: âŒ éªŒè¯å¤±è´¥ - {result.get('error', 'Unknown')}\n")
                    f.write("\n")
            
            logger.info(f"éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {project_dir}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜éªŒè¯ç»“æœå¤±è´¥: {e}")

    def get_validation_report(self, project_dir: Path) -> str:
        """è·å–éªŒè¯æŠ¥å‘Šæ–‡æœ¬"""
        try:
            summary_file = project_dir / "validation_summary.md"
            if summary_file.exists():
                with open(summary_file, 'r', encoding='utf-8') as f:
                    return f.read()
            
            # å¦‚æœmarkdownæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è¯»å–ç®€åŒ–æŠ¥å‘Š
            simple_report_file = project_dir / "validation_report.txt"
            if simple_report_file.exists():
                with open(simple_report_file, 'r', encoding='utf-8') as f:
                    return f.read()
            
            return "æœªæ‰¾åˆ°éªŒè¯æŠ¥å‘Šæ–‡ä»¶"
            
        except Exception as e:
            logger.error(f"è¯»å–éªŒè¯æŠ¥å‘Šå¤±è´¥: {e}")
            return f"è¯»å–éªŒè¯æŠ¥å‘Šå¤±è´¥: {str(e)}"

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # è¿™é‡Œéœ€è¦æœ‰æ•ˆçš„APIå¯†é’¥è¿›è¡Œæµ‹è¯•
    test_api_key = "your-api-key-here"
    test_base_url = "https://api.openai.com/v1"
    
    if test_api_key != "your-api-key-here":
        validator = VLMValidator(test_api_key, test_base_url)
        
        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡è·¯å¾„
        test_project_dir = Path("test_project")
        test_project_dir.mkdir(exist_ok=True)
        
        # æµ‹è¯•æ‰¹é‡éªŒè¯
        try:
            result = validator.validate_batch_images(test_project_dir)
            if result["success"]:
                print(f"æ‰¹é‡éªŒè¯æˆåŠŸ: {result['successful_validations']}/{result['total_images']}")
                print("\néªŒè¯æŠ¥å‘Š:")
                print(validator.get_validation_report(test_project_dir))
            else:
                print(f"æ‰¹é‡éªŒè¯å¤±è´¥: {result['error']}")
        except Exception as e:
            print(f"æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("è¯·è®¾ç½®æœ‰æ•ˆçš„APIå¯†é’¥è¿›è¡Œæµ‹è¯•")
